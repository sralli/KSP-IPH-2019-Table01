{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import necessary packages\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from keras.utils import get_file\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import cvlib as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# download pre-trained model file (one-time download)\n",
    "dwnld_link = \"https://github.com/arunponnusamy/cvlib/releases/download/v0.2.0/gender_detection.model\"\n",
    "model_path = get_file(\"gender_detection.model\", dwnld_link,\n",
    "                     cache_subdir=\"pre-trained\", cache_dir=os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['man','woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivamralli/anaconda3/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "model_res = ResNet50(weights='imagenet', include_top=False,\n",
    "                 input_shape=(224, 224, 3))\n",
    "def extract_features(img_path, model):\n",
    "    input_shape = (224, 224, 3)\n",
    "    img = image.load_img(img_path, target_size=(\n",
    "        input_shape[0], input_shape[1]))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / norm(flattened_features)\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def man_or_woman(img):\n",
    "    image = cv2.imread(img)\n",
    "    face, confidence = cv.detect_face(image)\n",
    "    for idx, f in enumerate(face):\n",
    "\n",
    "         # get corner points of face rectangle       \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "\n",
    "        # draw rectangle over face\n",
    "        #cv2.rectangle(image, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "\n",
    "        # crop the detected face region\n",
    "        face_crop = np.copy(image[startY:endY,startX:endX])\n",
    "\n",
    "        # preprocessing for gender detection model\n",
    "        face_crop = cv2.resize(face_crop, (96,96))\n",
    "        face_crop = face_crop.astype(\"float\") / 255.0\n",
    "        face_crop = img_to_array(face_crop)\n",
    "        face_crop = np.expand_dims(face_crop, axis=0)\n",
    "\n",
    "        # apply gender detection on face\n",
    "        conf = model.predict(face_crop)[0]\n",
    "        idx = np.argmax(conf)\n",
    "        print(idx)\n",
    "        if(classes[idx]=='man'):\n",
    "            return 'man'\n",
    "        elif(classes[idx]=='woman'):\n",
    "            return 'woman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_search = 'data/missing_images/realigned/2.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "val = man_or_woman(img_to_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "if val=='woman':\n",
    "    filenames = pickle.load(open('resnet_filenames_woman.pickle', 'rb'))\n",
    "    feature_list = pickle.load(open('resnet_features_woman.pickle', 'rb'))\n",
    "elif val=='man':\n",
    "    filenames = pickle.load(open('resnet_filenames_man.pickle', 'rb'))\n",
    "    feature_list = pickle.load(open('resnet_features_man.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_of_img = extract_features(img_to_search, model_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting n nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('search_space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 643 ms, sys: 228 ms, total: 871 ms\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "neighbors = NearestNeighbors(n_neighbors=100, algorithm='brute',\n",
    "metric='euclidean').fit(feature_list)\n",
    "distances, indices = neighbors.kneighbors([feature_of_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 82, 210, 258,  23,  45,  55, 251, 124,  49, 231,  34, 253,  59,\n",
       "        125, 256, 103, 203, 238, 207, 239,  99, 235,  89, 119, 197,  29,\n",
       "        247, 109, 227, 194, 111,  38, 205, 221,  63, 146, 248, 100, 116,\n",
       "        224, 138, 250,  47,  44, 118, 244,  90, 192, 223,  75, 260,  32,\n",
       "        106,  95,  39, 255, 236,  27,  97, 145, 222, 150,  50, 242, 104,\n",
       "         51, 228, 229, 157, 122,  24, 219,  80, 261,  69,  94, 245, 241,\n",
       "        198, 220, 202, 152, 225,  84, 237, 193, 117, 212, 128, 158,  40,\n",
       "         92, 214, 246, 217, 252, 160, 127, 121, 200]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman/ArrestPersonArrestPerson1936.png'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[indices[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices[0])):\n",
    "    img_name = filenames[indices[0][i]]\n",
    "    img = cv2.imread(img_name)\n",
    "    if val=='woman':\n",
    "        sp = 'search_space/'+img_name[6:]\n",
    "    elif val=='man':\n",
    "        sp = 'search_space/'+img_name[4:]\n",
    "    #print(sp)\n",
    "    cv2.imwrite(sp,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
